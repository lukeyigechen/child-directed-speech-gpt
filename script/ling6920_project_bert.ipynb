{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uy3GeHeUXuBA"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ],
      "id": "Uy3GeHeUXuBA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unusual-albert"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from ast import literal_eval\n",
        "from transformers import BertForSequenceClassification, Trainer, TrainingArguments, BertModel, RobertaForSequenceClassification, AutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer, BertTokenizer, BertTokenizerFast, BertConfig, RobertaTokenizer\n",
        "from datasets import Dataset\n",
        "import torch\n",
        "import numpy as np\n",
        "from scipy.special import softmax, expit\n",
        "\n",
        "import os\n",
        "#os.environ['CUDA_VISIBLE_DEVICES']='1'"
      ],
      "id": "unusual-albert"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CKU1mkN1gMiP"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "def setup_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "setup_seed(seed_val)"
      ],
      "id": "CKU1mkN1gMiP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dq6XZGo1gerZ"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "id": "dq6XZGo1gerZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNVlrh6gXwb0"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "xNVlrh6gXwb0"
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -av /content/drive/MyDrive/CUHK/ling6920/yc-data-4-23-2 /content/data"
      ],
      "metadata": {
        "id": "C2Wx9j0OWlp6"
      },
      "id": "C2Wx9j0OWlp6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NM_yg-b-VaCO"
      },
      "outputs": [],
      "source": [
        "def read_file(file):\n",
        "    with open(file) as f:\n",
        "        lines = f.readlines()\n",
        "    return lines"
      ],
      "id": "NM_yg-b-VaCO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2LZIW5L5zku"
      },
      "outputs": [],
      "source": [
        "def write_output(file, str_in):\n",
        "    with open(file, 'w') as f:\n",
        "        f.write(str_in)"
      ],
      "id": "p2LZIW5L5zku"
    },
    {
      "cell_type": "code",
      "source": [
        "list_file_name = ['/content/data/train.txt', '/content/data/dev.txt', '/content/data/test.txt']\n",
        "dict_sent_list = dict()\n",
        "for file in list_file_name: \n",
        "    list_sent = read_file(file)\n",
        "    new_list_sent = ['sentence\\tlabel']\n",
        "    for sent in list_sent:\n",
        "        sent = sent.strip()\n",
        "        if '[SEP]' in sent and '[AGE=' in sent:\n",
        "            split_sep = sent.split('[SEP]')[0]\n",
        "            split_age = split_sep.split('[AGE=')\n",
        "            for seq_age in split_age:\n",
        "                if ']' in seq_age:\n",
        "                    split_seq_age = seq_age.split(']')\n",
        "                    age_info = split_seq_age[0]\n",
        "                    text_info = ']'.join(split_seq_age[1:]).replace('\\t', ' ').strip()\n",
        "                    new_list_sent.append(text_info + '\\t' + age_info)\n",
        "                #else:\n",
        "                #    print(seq_age)\n",
        "    dict_sent_list[file] = new_list_sent\n",
        "    write_output(file.split('.txt')[0] + '_label.tsv', '\\n'.join(new_list_sent))"
      ],
      "metadata": {
        "id": "IDJjfSSaP8bY"
      },
      "id": "IDJjfSSaP8bY",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "td3UCVXqf4Pa"
      },
      "outputs": [],
      "source": [
        "train_df_voc = pd.read_csv('data/train_label.tsv', sep='\\t')[['sentence', 'label']]\n",
        "test_df_voc = pd.read_csv('data/test_label.tsv', sep='\\t')[['sentence', 'label']]\n",
        "valid_df_voc = pd.read_csv('data/dev_label.tsv', sep='\\t')[['sentence', 'label']]"
      ],
      "id": "td3UCVXqf4Pa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1e5oUAD55Mv"
      },
      "outputs": [],
      "source": [
        "train_df_voc.head()"
      ],
      "id": "I1e5oUAD55Mv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8zLoSktGL4P"
      },
      "outputs": [],
      "source": [
        "train_df_voc['label'].value_counts()"
      ],
      "id": "P8zLoSktGL4P"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GU6xgf5SFOXu"
      },
      "outputs": [],
      "source": [
        "def change_label(df):\n",
        "    for i, row in df.iterrows():\n",
        "        ifor_val = df.loc[i,'Intensity Class'].split(':')[0]\n",
        "        if int(ifor_val) < 0:\n",
        "            ifor_val = 1  # neg\n",
        "        elif int(ifor_val) > 0:\n",
        "            ifor_val = 2  # pos\n",
        "        else: \n",
        "            ifor_val = 0  # neu\n",
        "        df.at[i,'Intensity Class'] = ifor_val\n",
        "    return df"
      ],
      "id": "GU6xgf5SFOXu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EqpARv3Hgzru"
      },
      "outputs": [],
      "source": [
        "def make_dataset(df, tokenizer):\n",
        "  dataset_train = Dataset.from_pandas(df)\n",
        "  dataset_train = dataset_train.map(lambda e: tokenizer(e['sentence'], truncation=True, padding='max_length', max_length=128), batched=True)\n",
        "  dataset_train.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
        "  return dataset_train"
      ],
      "id": "EqpARv3Hgzru"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upper-right"
      },
      "outputs": [],
      "source": [
        "def train_model(train_df, valid_df, model_name, dir_model, num_labels):\n",
        "  print('-----train-----')\n",
        "\n",
        "  if model_name == 'bert':\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "  elif model_name == 'roberta':\n",
        "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "  elif model_name == 'bertweet':\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False)\n",
        "\n",
        "  dataset_train = make_dataset(train_df, tokenizer)\n",
        "  dataset_val = make_dataset(valid_df, tokenizer)\n",
        "\n",
        "  training_args = TrainingArguments(\n",
        "                  output_dir='./'+dir_model,          # output directory\n",
        "                  num_train_epochs=8,              # total # of training epochs\n",
        "                  per_device_train_batch_size=32,  # batch size per device during training\n",
        "                  per_device_eval_batch_size=16,   # batch size for evaluation\n",
        "                  warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "                  weight_decay=0.01,               # strength of weight decay\n",
        "                  logging_dir='./logs_'+dir_model,            # directory for storing logs\n",
        "                  #evaluation_strategy=\"steps\",\n",
        "                  evaluation_strategy=\"epoch\",\n",
        "                  save_strategy=\"epoch\",\n",
        "                  load_best_model_at_end = True,\n",
        "                  seed=seed_val,\n",
        "                  overwrite_output_dir=True,\n",
        "  )\n",
        "\n",
        "  if model_name == 'bert':\n",
        "    model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
        "  elif model_name == 'roberta':\n",
        "    model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=num_labels)\n",
        "  elif model_name == 'bertweet':\n",
        "    model = AutoModelForSequenceClassification.from_pretrained('vinai/bertweet-base', num_labels=num_labels)\n",
        "\n",
        "  #model = model.to(device)\n",
        "  model.train()\n",
        "\n",
        "  trainer = Trainer(\n",
        "      model=model,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
        "      args=training_args,                  # training arguments, defined above\n",
        "      train_dataset=dataset_train,         # training dataset\n",
        "      eval_dataset=dataset_val,            # evaluation dataset\n",
        "  )\n",
        "\n",
        "  trainer.train()\n",
        "  \n",
        "  return tokenizer, trainer\n"
      ],
      "id": "upper-right"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhqEG8FzSll0"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, precision_recall_fscore_support"
      ],
      "id": "HhqEG8FzSll0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FphVMfIBhlsN"
      },
      "outputs": [],
      "source": [
        "def eval_model(trainer, test_df, tokenizer, overall_types):\n",
        "  print('-----eval-----')\n",
        "  dataset_test = make_dataset(test_df, tokenizer)\n",
        "  predict_data = trainer.predict(dataset_test)\n",
        "  metrics = predict_data.metrics\n",
        "  print(metrics)\n",
        "  #print(np.argmax(predict_data.predictions, axis=1).flatten())\n",
        "  pre_labels = np.argmax(predict_data.predictions, axis=1).flatten()\n",
        "  test_df['predictions'] = pd.Series(pre_labels)\n",
        "\n",
        "  #write_out(overall_types, metrics)\n",
        "  y_true = test_df['label'].values.tolist()\n",
        "  y_pred = test_df['predictions'].values.tolist()\n",
        "  report = classification_report(y_true, y_pred)\n",
        "  print(report)\n",
        "\n",
        "  precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
        "  acc = accuracy_score(y_true, y_pred)\n",
        "  print('precision: ' + str(precision))\n",
        "  print('recall: ' + str(recall))\n",
        "  print('f1: ' + str(f1))\n",
        "  print('accuracy: ' + str(acc))\n",
        "\n",
        "  return metrics, test_df"
      ],
      "id": "FphVMfIBhlsN"
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = 8"
      ],
      "metadata": {
        "id": "shNE4IjoS13-"
      },
      "id": "shNE4IjoS13-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crucial-monitor"
      },
      "outputs": [],
      "source": [
        "# voc, bert\n",
        "\n",
        "tokenizer, trainer_voc = train_model(train_df_voc, valid_df_voc, 'bert', 'voc-bert', num_labels)\n",
        "\n",
        "metrics_voc, pred_df_voc = eval_model(trainer_voc, test_df_voc, tokenizer, 'voc-bert')\n",
        "pred_df_voc.to_csv('pred_df_voc-bert.csv', index=False)\n",
        "\n",
        "trainer_voc.save_model('./model_save_voc-bert')"
      ],
      "id": "crucial-monitor"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}