{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rK7TELCDUQRo"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMFHlbF7UUVZ"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import sys\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from transformers import GPT2Tokenizer, GPT2Model, GPT2Config, GPT2LMHeadModel, LineByLineTextDataset, DataCollatorForLanguageModeling, Trainer, TrainingArguments, pipeline, set_seed\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "from tokenizers import ByteLevelBPETokenizer\n",
        "import json\n",
        "import os\n",
        "from datasets import load_metric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQCNY9mFVJLJ"
      },
      "outputs": [],
      "source": [
        "epoch_num = 30\n",
        "seed_global = 42\n",
        "metric = load_metric('accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3w-TRdrVLF-"
      },
      "outputs": [],
      "source": [
        "def compute_metrics_accuracy(eval_pred):\n",
        "    global metric\n",
        "    predictions, labels = eval_pred\n",
        "    predictions.to('cpu')\n",
        "    labels.to('cpu')\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7DV_e8lVO_w"
      },
      "outputs": [],
      "source": [
        "def setup_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqEBVVPSVTpE"
      },
      "outputs": [],
      "source": [
        "def prep_gpt2_tokenizer():\n",
        "    # path_ex = data_path\n",
        "    # Initialize a tokenizer\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]', 'sep_token': '[SEP]'})\n",
        "    # Customize training\n",
        "    return tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyXHFxwAVV7B"
      },
      "outputs": [],
      "source": [
        "def model_prep(tokenizer, train_data_dir, dev_data_dir, model_train_dir):\n",
        "    global epoch_num, seed_global\n",
        "    # config and train model\n",
        "    #configuration = GPT2Config()\n",
        "    #model = GPT2LMHeadModel(config=configuration)\n",
        "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "    model.resize_token_embeddings(len(tokenizer))\n",
        "    dataset_train = LineByLineTextDataset(\n",
        "        tokenizer=tokenizer,\n",
        "        file_path=train_data_dir,\n",
        "        block_size=128,\n",
        "    )\n",
        "    dataset_dev = LineByLineTextDataset(\n",
        "        tokenizer=tokenizer,\n",
        "        file_path=dev_data_dir,\n",
        "        block_size=128,\n",
        "    )\n",
        "    data_collator = DataCollatorForLanguageModeling(\n",
        "        tokenizer=tokenizer, mlm=False,\n",
        "    )\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=model_train_dir,\n",
        "        logging_dir=os.path.join(model_train_dir, '/logs'),\n",
        "        overwrite_output_dir=True,\n",
        "        num_train_epochs=epoch_num,\n",
        "        per_device_train_batch_size=32,  # batch size per device during training\n",
        "        per_device_eval_batch_size=16,  # batch size for evaluation\n",
        "        # save_steps=10000,\n",
        "        # save_total_limit=2,\n",
        "        warmup_steps=500,  # number of warmup steps for learning rate scheduler\n",
        "        weight_decay=0.01,  # strength of weight decay\n",
        "        learning_rate=0.00005, #0.00025, #was 0.00005\n",
        "        # prediction_loss_only=True,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        # save_total_limit=10,\n",
        "        seed=seed_global,\n",
        "    )\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        data_collator=data_collator,\n",
        "        train_dataset=dataset_train,\n",
        "        eval_dataset=dataset_dev,\n",
        "        # compute_metrics=compute_metrics_accuracy,\n",
        "        # CUDA_LAUNCH_BLOCKING=1,\n",
        "    )\n",
        "    return trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NM_yg-b-VaCO"
      },
      "outputs": [],
      "source": [
        "def read_file(file):\n",
        "    with open(file) as f:\n",
        "        lines = f.readlines()\n",
        "    return lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2LZIW5L5zku"
      },
      "outputs": [],
      "source": [
        "def write_output(file, str_in):\n",
        "    with open(file, 'w') as f:\n",
        "        f.write(str_in)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjPS2ZidjYll"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KS_A3g_-4dpn"
      },
      "outputs": [],
      "source": [
        "!cp -av /content/drive/MyDrive/CUHK/ling6920/MacWhinney /content/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4J9rmsp7lPXQ"
      },
      "outputs": [],
      "source": [
        "list_cha_file = []\n",
        "for file in os.listdir(\"data\"):\n",
        "    if file.endswith(\".cha\"):\n",
        "        list_cha_file.append(os.path.join(\"data\", file))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yx-TqcxrpfBs"
      },
      "outputs": [],
      "source": [
        "list_cha_file.sort()\n",
        "print(list_cha_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7w0woTQo2hv"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqwRk1HSlERw"
      },
      "outputs": [],
      "source": [
        "dict_data = OrderedDict()\n",
        "dict_chi_age = dict()\n",
        "dict_mar_age = dict()\n",
        "for file in tqdm(list_cha_file):\n",
        "    idx_sub = 0\n",
        "    input_lines = read_file(file)\n",
        "    list_sent = []\n",
        "    tmp_save = ''\n",
        "    age_chi_tmp = '-1'\n",
        "    age_mar_tmp = '-1'\n",
        "    for line in input_lines:\n",
        "        line = line.strip()\n",
        "        if line.startswith('*'): # begin to save\n",
        "            tmp_save += line\n",
        "        elif line.startswith('%mor'): # stop and save\n",
        "            list_sent.append(tmp_save)\n",
        "            tmp_save = ''\n",
        "        elif line.startswith('@New Episode'): # save prev list_sent to dict\n",
        "            if tmp_save != '':\n",
        "                list_sent.append(tmp_save)\n",
        "            tmp_save = ''\n",
        "            dict_data[file + str(idx_sub)] = list_sent\n",
        "            list_sent = []\n",
        "            idx_sub += 1\n",
        "        elif '|MacWhinney|CHI|' in line:\n",
        "            age_chi_tmp = line.split('|')[3]\n",
        "        elif '|MacWhinney|MAR|' in line:\n",
        "            age_mar_tmp = line.split('|')[3]\n",
        "    dict_data[file + str(idx_sub)] = list_sent\n",
        "    dict_chi_age[file] = age_chi_tmp\n",
        "    dict_mar_age[file] = age_mar_tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCCHo1p65qWE"
      },
      "outputs": [],
      "source": [
        "dict_chi_age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EO_pucEyzJ1K"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5opPP1pYyz_x"
      },
      "outputs": [],
      "source": [
        "def proc_sent_format(str_in):\n",
        "    sent_speaker_split = str_in.split(':\\t')\n",
        "    speaker = sent_speaker_split[0][1:]\n",
        "    #print(speaker)\n",
        "    sent_raw = ' '.join(sent_speaker_split[1:])\n",
        "    split_play_icon = sent_raw.split('\u0015')[0]\n",
        "    #print(split_play_icon)\n",
        "    # TODO for now I keep all that's in [], () and <>\n",
        "    return speaker, split_play_icon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzNFPA2A_-xp"
      },
      "outputs": [],
      "source": [
        "def dict_add_one(dict_in, item_in):\n",
        "    if item_in not in dict_in:\n",
        "        dict_in[item_in] = 0\n",
        "    dict_in[item_in] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5WIvpLNsO4m"
      },
      "outputs": [],
      "source": [
        "# do not differentiate ages for the time being\n",
        "dict_speaker = dict()\n",
        "dict_counter = dict()\n",
        "processed_sent = []\n",
        "for idx_name, sent_list in dict_data.items(): \n",
        "\n",
        "    #age_chi = idx_name.split('/')[1][1:2]\n",
        "    age_chi = dict_chi_age[idx_name.split('.cha')[0] + '.cha'].split(';')[0]\n",
        "    age_mar = dict_mar_age[idx_name.split('.cha')[0] + '.cha'].split(';')[0]\n",
        "\n",
        "    if len(sent_list) > 0:\n",
        "        #print(sent_list[0])\n",
        "        last_speaker = -1\n",
        "        last_speaker_str = ''\n",
        "        tmp_save_list = []\n",
        "        \n",
        "        for sent in sent_list:\n",
        "            speaker, text = proc_sent_format(sent)\n",
        "            if speaker not in dict_speaker:\n",
        "                dict_speaker[speaker] = 0\n",
        "            dict_speaker[speaker] += 1\n",
        "            # TODO only use FAT, CHI, MOT, MAR\n",
        "            speaker_str = speaker\n",
        "            if speaker == 'CHI' or speaker == 'MAR':\n",
        "                speaker = 1\n",
        "            elif speaker == 'FAT' or speaker == 'MOT':\n",
        "                speaker = 0\n",
        "            else:\n",
        "                speaker = 2 \n",
        "\n",
        "            if speaker != 0 and last_speaker == 0:\n",
        "                tmp_str = ' '.join(tmp_save_list)\n",
        "                processed_sent.append(tmp_str)\n",
        "                tmp_save_list = []\n",
        "                dict_add_one(dict_counter, age_chi)\n",
        "            if speaker_str == 'CHI' and last_speaker_str != speaker_str:\n",
        "                tmp_save_list.append('[AGE=' + age_chi + ']')\n",
        "            elif speaker_str == 'MAR' and last_speaker_str != speaker_str:\n",
        "                tmp_save_list.append('[AGE=' + age_mar + ']')\n",
        "            if speaker == 0 and last_speaker != 0:\n",
        "                if last_speaker_str == 'CHI':\n",
        "                    tmp_save_list.append('[SEP]')\n",
        "                elif last_speaker_str == 'MAR':\n",
        "                    tmp_save_list.append('[SEP]')\n",
        "            if speaker != 2:\n",
        "                tmp_save_list.append(text)\n",
        "            last_speaker = speaker\n",
        "            last_speaker_str = speaker_str\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21C_U6P_816_"
      },
      "outputs": [],
      "source": [
        "for str_t in processed_sent:\n",
        "    for i in range(8):\n",
        "        if ('[AGE=' + str(i)) in str_t and ('[AGE=' + str(i+2)) in str_t:\n",
        "            print(str_t)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_htduHB3BXFm"
      },
      "outputs": [],
      "source": [
        "dict_counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wu6IWLJkJS6Q"
      },
      "outputs": [],
      "source": [
        "dict_speaker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dhjz6uD6Bc8"
      },
      "outputs": [],
      "source": [
        "random.shuffle(processed_sent)\n",
        "print(len(processed_sent))\n",
        "len_processed_sent = int(len(processed_sent) * 0.8)\n",
        "len_processed_sent_test = int(len(processed_sent) * 0.9)\n",
        "print(len_processed_sent)\n",
        "print(len_processed_sent_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcBTyAF16S97"
      },
      "outputs": [],
      "source": [
        "write_output('data/train.txt', '\\n'.join(processed_sent[:len_processed_sent]))\n",
        "write_output('data/dev.txt', '\\n'.join(processed_sent[len_processed_sent:len_processed_sent_test]))\n",
        "write_output('data/test.txt', '\\n'.join(processed_sent[len_processed_sent_test:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXRqnTOQAV21"
      },
      "outputs": [],
      "source": [
        "!cp /content/data/train.txt /content/drive/MyDrive/CUHK/ling6920/yige/yc-data-4-23-2/train.txt\n",
        "!cp /content/data/dev.txt /content/drive/MyDrive/CUHK/ling6920/yige/yc-data-4-23-2/dev.txt\n",
        "!cp /content/data/test.txt /content/drive/MyDrive/CUHK/ling6920/yige/yc-data-4-23-2/test.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DOySdV5Vaks"
      },
      "outputs": [],
      "source": [
        "setup_seed(seed_global)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uq2sbOOdZ986"
      },
      "outputs": [],
      "source": [
        "print('preparing the tokenizer...')\n",
        "# tokenizer = prep_tokenizer(os.path.join(sys.argv[2], 'stock_return_str_conv.txt'))\n",
        "# tokenizer.save_model(sys.argv[4])\n",
        "tokenizer = prep_gpt2_tokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xF2prW7m7vim"
      },
      "outputs": [],
      "source": [
        "output = tokenizer('well (.) how_about to your friends ?  [SEP] them too . ')[\"input_ids\"]\n",
        "print(output[10])\n",
        "print(tokenizer.decode(output[10]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96ne3nu-aBCS"
      },
      "outputs": [],
      "source": [
        "print('checking the device...')\n",
        "print('CUDA: ' + str(torch.cuda.is_available()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sTfKbeX_aCZq"
      },
      "outputs": [],
      "source": [
        "print('preparing the model...')\n",
        "trainer = model_prep(tokenizer, 'data/train.txt', 'data/dev.txt', 'tmp')\n",
        "print('training the model...')\n",
        "trainer.train()\n",
        "print('saving the model...')\n",
        "trainer.save_model('model')\n",
        "\n",
        "print('training all set!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a2rLQg7urtGi"
      },
      "outputs": [],
      "source": [
        "str_check = \"[AGE=3] Daddy did they have shoes .  [SEP] \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXSF4k-ID849"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, set_seed\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('model')\n",
        "\n",
        "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odxKTTFVbCil"
      },
      "outputs": [],
      "source": [
        "generator(str_check, max_length=40, num_return_sequences=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sgs9F9OCoUsm"
      },
      "outputs": [],
      "source": [
        "# load checkpoint\n",
        "tokenizer = prep_gpt2_tokenizer()\n",
        "\n",
        "model = GPT2LMHeadModel.from_pretrained('model-4-23-2')\n",
        "\n",
        "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRwNAQsyogLa"
      },
      "outputs": [],
      "source": [
        "for i in range(8):\n",
        "    str_concat = '[AGE=' + str(i) + '] ' + str_check\n",
        "    print(i)\n",
        "    print(generator(str_concat, max_length=40, num_return_sequences=1))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}